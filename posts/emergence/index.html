<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Emergence of Complex Skills in Language Model | 霄岚侠客</title>
<meta name=keywords content><meta name=description content="Deep Exploration of Theory on Emergence of Large Language Model"><meta name=author content="Xiaolan Liu (Supervised by Prof Suvrit Sra)"><link rel=canonical href=https://XIAOLAN-design.github.io/posts/emergence/><link crossorigin=anonymous href=/assets/css/stylesheet.31f4132a2294f1e65473d35247f033434cb9dd6a137282653a99e81b00af7db8.css integrity="sha256-MfQTKiKU8eZUc9NSR/AzQ0y53WoTcoJlOpnoGwCvfbg=" rel="preload stylesheet" as=style><link rel=icon href=https://XIAOLAN-design.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://XIAOLAN-design.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://XIAOLAN-design.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://XIAOLAN-design.github.io/apple-touch-icon.png><link rel=mask-icon href=https://XIAOLAN-design.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://XIAOLAN-design.github.io/posts/emergence/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Emergence of Complex Skills in Language Model"><meta property="og:description" content="Deep Exploration of Theory on Emergence of Large Language Model"><meta property="og:type" content="article"><meta property="og:url" content="https://XIAOLAN-design.github.io/posts/emergence/"><meta property="og:image" content="https://XIAOLAN-design.github.io/images/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-07-05T00:00:00+00:00"><meta property="article:modified_time" content="2024-07-05T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://XIAOLAN-design.github.io/images/papermod-cover.png"><meta name=twitter:title content="Emergence of Complex Skills in Language Model"><meta name=twitter:description content="Deep Exploration of Theory on Emergence of Large Language Model"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://XIAOLAN-design.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Emergence of Complex Skills in Language Model","item":"https://XIAOLAN-design.github.io/posts/emergence/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Emergence of Complex Skills in Language Model","name":"Emergence of Complex Skills in Language Model","description":"Deep Exploration of Theory on Emergence of Large Language Model","keywords":[],"articleBody":"This Blog is devided into 2 parts. First part is the review of discussion of Emergence. You can just skip part 2 if you are not interested in theoretical staff. Second part illustrates the theory of emergence of complex skills in language model in a way people can understand easily, which is based on (Sanjeev et al. 2023) and the modified version of the paper Prof Arora (the author of the paper) sent me. Many thanks for the modified version of the paper and his comments on this blog.\nThe motivation for this blog is to make the relating theory easy for people to understand, so I put more illustration work on this blog but not omit some important theoretical staff. All of the formal definitions, assumptions and theorems in this paper are from those two resources above and other relating papers that I will refer later.\nThe first contribution is that I explained a few concepts in the paper in more detail. For example, in the 1st part of the blog, I gave a full review about what is emergence and what is the emergence of complex skills which the authors didn’t explain well. In the 2nd part, I wrote down the intuitions of the main theorems and how they were connected to the LLM which was not covered in the original paper.\nThe second contribution is that I added the proofs of a few statements which the author skipped in his paper (see Appendix 3.1, 3.2). I also reconstructed the proof of some theorems in a simpler way(see Appendix 3.3).\nConsidering the paper (Sanjeev et al. 2023) is not finalized, thus this blog cannot be yet finalized,too. I will keep it updated once I recieved more information from Professor Arora.\nPart 1: Discussion of Emergence The exsitance of emergence has been a hated topic recently. The debate mainly comes from different definition of emergence, thus we will review all of the definitions in the following.\n1 Real Defintion of Emergence Emergence is a popular phenomena in domains such as physics, biology, etc. The general definition of emergence, adapted from Steinhardt (2022) and rooted in a 1972 essay called “More Is Different” by Nobel prize-winning physicist Philip Anderson (Anderson, 1972):\nQuantitative changes in a system result in qualitative changes in behavior. The emergent abilities of large language models also attract lots of attention recentlly. However, the official definition of Emergence of Language Models remains in hated discussion.\n1.1 Outdated Definition of Emergence (Wei et al. 2022) first introduced emergent abilities of large language models, it was defined as following:\nSharpness, transitioning seemingly instantaneously from not present to present. Unpredictability, transitioning at seemingly unforeseeable model scales Figure 1: see (Wei et al. 2022). Eight examples of emergence in the few-shot prompting setting. Each point is a separate model. The ability to perform a task via few-shot prompting is emergent when a language model achieves random performance until a certain scale, after which performance significantly increases to well-above random.\nFigure 2:see (Wei et al. 2022). Analogous figure with number of model parameters instead of training flops in figure 1. Obviously it shows Figure 1 and figure 2 have the exactly same performance, which means models that used more training compute also typically have more parameters—hence.\n1.2 Is Emergence a Mirage? However, there was a time that people both from industry and academia doubted the existance of Emergent Abilities for language models. They argued those models actually do not show Sharpness,transitioning, unpredictability performance improvement when the model is scaled up, thus do not have Emergent Abilities.\nThere is no doubt the model gets better performance with more number of parameters and training flops.\nBut is the better performance just the sum of small improvement of each scaling up stage or is it greater than sum of those? Whether the sharp transition of the performance curve come from the choice of evaluation of metrics? see more in (Emergent Abilities Are a Mirage) Figure 3:see (Schaeffer et al. 2023). Claimed emergent abilities evaporate upon changing the metric. Left to Right: Mathematical Model, 2-Integer 2-Digit Multiplication Task, 2-Integer 4-Digit Addition Task. Top: When performance is measured by a nonlinear metric (e.g., Accuracy), the InstructGPT/GPT-3 [3, 24] family’s performance appears sharp and unpredictable on longer target lengths. Bottom: When performance is instead measured by a linear metric (e.g., Token Edit Distance), the family exhibits smooth, predictable performance improvements.\n(Schaeffer et al. 2023) conducted lots of experiments to prove that the sharpness, transitioning and unpredictability performance improvment of large language model is a creation of chosen metrics. Typically, linear or continuous metrics produce smooth,continuous,predictable changes in model performance, while a nonlinear or discontinuous metric can distort the model family’s performance from continuous, predictable changes to appear sharp, unpredictable.\nHowever, the explanation of metric choice above cannot be the evidence to deny the exsitance of emergent abilities. Since eventhough the performance does not show sharp transitioning, the improvement is still unpredictable to some extent.\nAs picture above shows, the performance improvement does not follow a deterministic function of scaling , which means it is unpredictable.\nAlso, the increasing rate of performance improvement is getting bigger and bigger, which means the performance improvement is greater than sum of small improvement of each scaling up stage, which obviously support that new skills will be emergent in large models.\n1.3 Latest Defition of Emergence Slow emergence is more widely accepted recently, meaning that the performance curve does not have to appear as a sharp transition when the model is scaled up. The sharp transition might be due to the final step metric evaluation method we used for meausring model performance. That is: solving one task reguires several steps, the models performance is actually incresing in each scaling step. but the evaluation metric just count for final step, which will result in the sharp transition of performance curve.\nEmergence is firstly introduced as Slow Emergence by (Sanjeev et al. 2023), which is defined as follows:\nAs number of sample sizes and number of parameters increase together then the model’s performance on a broad range of language tasks improves in a correlated way. I personally do not totally agree with the definition above. I agree that the performance curve does not have to be sharp transition part, but the performance increasement should be 1+1\u003e2, which means the better performance is not the sum of small improvement of each scaling up stage, it should be greater than sum of those. however, the definition above does not illustrate 1+1\u003e2.\nIn the paper by (Sanjeev et al. 2023), emergence of simple skills is defined as slow emergence above. Emergence of complex skills is defined as something new (those were not seen during training means new things) emerge\nThere are further discussion about emergence, (Lu et al. 2023) firstly mentioned Emergent abilities are In-context Learning. At the moment I will not extend this part.\nPart 2: theory of emergence of complex skills in language model I will first give a intuition about why complex skills emerge in language models. We have a text corpus, the the size of the training corpus is almost same with number of simple skills. We define complex skill as k’-tuple skill, which is composed of k’ simple skills (you can find details about definitions about corpus and skills below).\nAssume we have 1000 training size and 1000 simple skills, 5 simple skills(k'=5) can compose a complex skill, thus we have \\(1000^{5}\\) =\\(10^{15}\\)combinations of complex skills. Since the training size is 1000, it can only see 1000/\\(10^{15}\\)=1/\\(10^{12}\\) proportion of complex skills during training(learning). We know that the model can only learn seen skills, if the model can only see 1/\\(10^{12}\\) proportion of complex skills during training, then it displays competence on complex skills is at most 1/\\(10^{12}\\) proportion. Thus if the model can display competency on even 10% proportion, which means the model emerges 10%-1/\\(10^{12}\\) complex skills despite it has never learned(seen during training) those complex skills. Thus, in order to show the emergence of complex skills, we need to show the competence of complex skills is at least not too small (bigger than e.g. 1/\\(10^{12}\\)), which means lots of new complex skills that are not seen during training process emerge. Here we introduce competence of simple skills to help us to quantify the competence of complex skills. If we can show that the competence of complex skill after scaling is at least the same level of competence of simple skills, which means the competence of complex skills is at least not too small since the competence of simple skills is not too small(since each simple skill will be seen thus be learned during training, so the competence of simple skills are not small).\nSo in part 2, the main goal is to quantify the competence of skills, then connect competence, scaling law and loss together to show that the competence of complex skill after scaling is at least the same level of competence of simple skills. Thus with the competence of complex skill bigger than the proportion of complex skills will be seen during training, we can conclude that the model can emerge new complex skills that are not seen during training when scaling up.\nThe structure of part 2 is as follows: we firstly introduce some basic knowledge for analyzing emergence in 2.1, 2.2 and 2.3. Then based on these, in 2.4.1 we analyze slow emergence(recall real definition of emergence in part 1) in language model from statistical view, which (Sanjeev et al. 2023) is as follows:\nAs the model’s excess cross entropy goes down due to scaling, the model’s performance improves.\nThen in 2.4.2 we continue introducing how complex skills(k’ skills) emerge due to scaling, the key result as follows shows that if we scale up the model, the performance we get for complex skills is equal to performance we get for simple skills without scaling (Sanjeev et al. 2023):\nIf models of size S have a certain success rate (compentence) at solving tasks that require k’ skills, then Scaling Laws imply that scaling up models (i.e. to size 10S leads to factor 2 reduction in loss) will give them the same success rate on tasks that involve combining 2k’ skills as what we get on k’ skills.\n2.1 Skills of Language Moldels First, we will clarify some terminologies required for this theory. There is no official definition for Skills of Language Model. Generally speaking, for those words generated by humanbeings or by neural network models, some skills are applied. (Sanjeev et al. 2023) develped a new theory as follows to describe skills as those for generating text pieces.\n2.1.1 Text Pieces Definition of Text Piece: (Sanjeev et al. 2023)\nThere is a measure \\(µ_{2}()\\) on these text-pieces, with \\(µ_{2}(t)\\) denoting the measure of text-piece t. The usual cross-entropy loss is computed by weighting text-pieces with respect to this measure. Assume we choose one piece of news from NewYork Times as our corpus, text piece should be thought of as having a size between a paragraph to a few pages, drawn from a longer corpus. Equivalently speaking, we can divide the news into text-pieces, each text pieces consitsts \\(C\\) tokens. We have train process and test process, thus corpus is devided as train corpus and test corpus, respectively. We will see in scling law introduced later that only test corpus is considered in this theory. --\u003e 2.1.2 Skills Definition of skill Graph: (Sanjeev et al. 2023)\nA skill graph is a bipartite graph \\((V_{1}, V_{2}, E)\\) where nodes in \\(V_{2}\\) correspond to skills, there is a measure \\(µ_{1}()\\) on these skills, with \\(µ_{1}(s)\\) denoting the measure of skill \\(s\\). Figure 4:see (Sanjeev et al. 2023). Each text piece can be generated by applying several skills.\nFor each text piece, skills are required for generating it. For the sentence above, What kinds of skills could it apply to generate the text pieces? You will have the answer after getting to know what do skills mean. We have example of skills as follows.\nNamed Entity Recognition (NER) pronoun disambiguation Sentiment Analysis Anaphora Resolution Logical Inference World Knowledge Barack Obama was born in Hawaii. He served as the 44th President of the United States. For the sentence above, Barack Obama is a name, Hawaii is a location, and the United States is a country, all of which can be determined by the skill Named Entity Recognition (NER). And by applying pronoun disambiguation can we infer He means Barack Obama.\nI love waiting in long lines. It makes me want to cut myself The sentence above is bit hard since it is an ironical expression, the word love here is not really love, it means hate instead, which requires the skill entiment analysis to analyze the sentiment of this expression is negative by the negative verb cut myself.\nThe CEO of the company made an announcement. It surprised everyone, so they get together to drink in the bar. It in the sentence means the thing he CEO of the company made an announcement, which requires the skill Anaphora Resolution. Since everyone is amazed by the god news, so we can infer everyone is happy, then they will celebrate in some place like in the bar, which requires the skill Logical Inference.\nThough I just list several skills for one sentence, the truth is when we generate the sentence, we have to apply almost every skills we want. the skills above are those named by human. However, there are more skills that are not found or named by human beings. For instance, those are lots of skills used in large language models like GPT, we human however cannot know each specific skills the model applies to generate text.\nAfter getting to know those examples above, a quick quiz for you: what kinds of skills could it apply to generate the following text pieces?\nThe city councilmen refused the demonstrators a permit because they feared violence.\n2.2 Cross Entropy Loss to Scaling Law Since we want to connect scaling law with skills, we can choose cross entropy as our bridge. We first find connection between cross entropy and scaling law, then we find connection between cross entropy and skills, thus we can find connection between scaling law and skills. So in this part, we are gonna first intriduce cross entropy then scaling law, then we will find connection between them.\n2.2.1 Cross Enrtopy For word generation, we always have a sequence of previous words to generate the next word, which is also named as next word prediction. Similar to other predicting process, language generating process also has 2 probability. One is the probability of the next predicted word of the current model, the other is the ground-truth probability (i.e. humans' choice), which can be understood as the true label for next word prediction process. Given the previous words \\(w_1 w_2 \\ldots w_i\\), the probability distribution of the model itself \\(q_{i}\\left(w\\right)\\), which can be defined as \\(\\operatorname{q}_i\\left[w \\mid w_1 w_2 \\ldots w_i\\right]\\). The ground truth distribution \\(p_{i}\\left(w\\right)\\) for generating the next \\((i + 1)th\\) word \\(w\\), which is defined as \\(\\operatorname{p}_i\\left[w \\mid w_1 w_2 \\ldots w_i\\right]\\). $$ p_{i}\\left(w\\right)\\ = \\begin{cases} 1, \u0026 \\text{if } w = w_{i+1} \\\\ 0. \u0026 \\text{if} w\\not =w_{i+1} \\end{cases}\\quad (1) $$ We take a particular interest in the difference between predicted word and the ground-truth word. The Cross Entropy can get a measure of dissimilarity between \\(p_{i}\\left(w\\right)\\) and \\(q_{i}\\left(w\\right)\\).Thus we introduce cross-entropy loss of the model on one word is: $$ \\sum_w p_i(w) \\log \\frac{1}{q_i(w)} \\quad(\\text {Cross Entropy of the word}) \\quad (2) $$ We have many attempts to make predictions, only one attempt is correct. That means only one attempt with ground-truth probability of 1, others are 0. So we sum all of the attempts (w) together to get the cross entropy on the ((i+1)th) word.\n$$ \\sum_w p_i(w_{i+1}) \\log \\frac{1}{q_i(w_{i+1})} = \\log \\frac{1}{q_i(w_{i+1})}\\quad (3) $$\nIt is easy to be confused between the Cross Entropy of the model and Cross Entropy of the word. Cross Entropy of the model is the total cross entropy of each word in the test corpus. After getting cross entropy of the word, we need to sum up all the cross entropy of the word to get the cross entropy of the model M.\n$$ \\ell(M)=\\sum_{i=1}^{N} \\log \\frac{1}{q_i(w_{i+1})} =-\\sum_{i=1}^{N} \\log q_i(w_{i+1}) \\quad (4) $$ which can be defined as follows: $$ =-\\sum_i \\log \\underset{M}{\\operatorname{Pr}}\\left[w_{i+1} \\mid w_1 w_2 \\ldots w_i\\right] \\quad \\text { (Cross Entropy of the Model) } \\quad (5) $$\nWe are also interested in the inherent property of language, we know human can have lots of choices for making the next word. Entropy can be used to describe the \"uncertainty\" inherent to the variable's possible outcomes. Thus we use Entropy to descibe inherent uncertainty of one word prediction: $$ \\sum_w p_i(w) \\log \\frac{1}{p_i(w)} \\quad(\\text {Entropy}) \\quad (6) $$ We also introduce KL divergence, which quantifies the information loss when the predicted distribution \\(q_{i}\\left(w\\right)\\) is used to approximate the true distribution \\(p_{i}\\left(w\\right)\\). it is also sometimes called excess entropy, is non-negative and defined as: $$ K L\\left(p_i \\| q_i\\right)=\\sum_w p_i(w) \\log \\frac{p_i(w)}{q_i(w)} \\quad(\\text {Excess Entropy}) \\quad (7) $$ Then we can find an intersting relationship on a per-word basis from equation\\((1),(2)\\) and \\((3)\\): $$ \\text { Corss Entropy }=\\text { Entropy }+ \\text { Excess Entropy} \\quad (8) $$ 2.2.2 Scaling Law Recall in part 1 we mentioned the real definition of Emergence:\nAs number of sample sizes and number of parameters increase together then the model’s performance on a broad range of language tasks improves in a correlated way.\nThe definition above reflects Scaling law, which describes how test cross entropy loss on test experiments scales with number of model parameters (N) and size of the dataset (D) Researchers have conducted lots of expiriments to derive Scaling law, Hoffmann et al. [2022] derived the scaling law is as follows:\n$$ L(N, D) = A + \\frac{B}{N^{0.34}} + \\frac{C}{D^{0.28}} \\quad A=1.61 \\quad B=406.4 \\quad C=410.7 \\quad (9) $$ 2.2.3 Understanding the Scaling Law in terms of excess entropy From [(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936), if we compare equation \\((9)\\) with \\((8)\\), the \\(A\\) term of \\((9)\\) captures the entropy of language. The lowest cross-entropy loss is entropy, that is term \\(A\\) for large corpora. The second and third terms of \\((9)\\) capture excess entropy, and they decrease polynomially with \\(N\\) and \\(D\\). For example when \\(D\\) is increased by a factor of 10 it reduces by roughly \\(10^{0.28} \\approx 2\\). This partly explains well the choice of metric evaluation could change the oerformance curve from sharp transition into slow increasement. As picture below shows: If we replace our loss metric from error rate as cross-entropy loss. We can observe the sharp transition of the perfromance curve disappear.\nThat is because the term \\(A\\) is a constant term, while the improvement of performance is brought by the sencond and third term. Thus, when there is some improvement for the sencond and third term, after we plus the first constant term \\(A\\), the curve will not show obvious improvement. Thus given the fact that excess cross entropy is the real driver in language generating process, it seems that we just need to consider **Excess Cross Entrioy** in our theory. Figure 5:see (Schaeffer et al. 2023). Adjacent plots for error rate, cross-entropy loss, and log probabilities of correct and incorrect responses on three classification tasks on BIG-Bench that we consider to demonstrate emergent abilities. Logical arguments only has 32 samples, which may contribute to noise. Error rate is (1 - accuracy).\n2.3 Skills modelling Skill modelling is a process of finding relationship between excess cross entropy and compentence on the skills. First we will make some assumptions, then we can quantify the model’s competence on particular skill.\n2.3.1 Mixing Assumption Each text-piece \\(t\\) can be generated by picking \\(k-tuple\\) of skills iid from measure \\(µ_{1}()\\) sing an unknown process, which assigns probability \\(µ_{2}(t)\\). Figure 6:Created by Xiaolan Liu. Skill graph where each text-piece t can be generated by picking k−tuple of skills .\nIt is assumed that we have a set of skills, which is pretty large and bit smaller than the number of text-pieces text pieces. Then text pieces are generated by picking random k-tuples of skills. l\n2.3.2 Scaling law Assumption The theory will assume scaling laws such as (9), thus it can reason directly about the model’s behavior on the test distribution We know the training corpus is quite large, which makes it hard to model our theory in training process. Luckily, the scaling laws help us avoid reasoning about training and generalization. The scaling law is based on test cross entropy loss, thus our theory does not need to refer to training cross entropy loss.\n2.3.3 Cloze Sufficiency Assumption To test the \\(k\\) underlying skills in \\(t\\), adds cloze prompts to \\(t\\) via an unknown process. The pre-trained model’s average prediction loss on Cloze questions (where the average is taken over the distribution of text pieces) closely tracks the excess cross-entropy of the model on classical next-word prediction.\nTheorem 1 in Appendix 3.1 justifies the exsitence of this assumption. You can find detailed math proof in Appendix.\nThe excess cross-entropy of the model on classical next-word prediction is not easy to calculate. Here we need to consider a equivalent method to get excess cross entropy loss, which is cloze questions approach. That means we add multiple choice question answering on text pieces to test the language model’s ability of understanding. Think the example below mentioned in (Sanjeev et al. 2023)\nThe city councilmen refused the demonstrators a permit because they feared violence.\nHere the pronoun they is ambiguous— grammar rules allow it to refer to either demonstrators or city councilmen. To test the model’s understanding of they in this sentence, we can append a prompt:\nQ. Who feared violence? A. city councilmen B.demonstrators\nAssume there are \\( N \\) text pieces in our model, we add \\( Q_i \\) cloze questions on this text piece above. The prediction loss on the text-piece above is the cross-entropy loss on predicting the answers to the cloze questions in it. The average prediction loss over all text-pieces is computed with respect to the measure \\(µ_{2}()\\), if we assume measure \\(µ_{2}()\\) is uniform. Then we have the average prediction loss over all text-pieces, noted as \\( \\delta \\), is defined as follows: \\[ \\delta = \\frac{1}{N} \\sum_{i=1}^N \\text{cross entropy on text piece } i \\] \\[ = \\frac{1}{N} \\sum_{i=1}^N \\frac{1}{Q_i} \\sum_{j=1}^{Q_i} \\text{cross entropy on cloze question } z_j^{(i)} \\] 2.3.4 compentence on the skills By cloze sufficiency assumption above, we replace model’s average prediction loss on Cloze questions as excess cross-entropy of the model on classical next-word prediction. Now we need to connect model’s average prediction loss on Cloze questions and compentence on the skills.\nFor a skill s, the competence of a model defined in the modified version of the paper Sanjeev sent to me: it is the expectation of the following random variable: randomly sample a text-piece containing that skill (this sampling uses the measure \\(µ_{2}(·)\\) on text-pieces) and measure the model’s success rate (1 - \\( \\delta \\)) at answering cloze questions in that text piece. We similarly define Competence on a tuple of skills (s1,s2,...,). 2.4 Analysis of Emergence Now we have set up a framework for modeling skills and connecting skills to the cross-entropy loss of the model, we firstly derive a mathematical formula for connections between loss, simple skills and scaling factor, then we have result: As the model’s excess cross entropy goes down due to scaling, the model’s performance on cloze tasks improves.\nAfter that, we derive a mathematical formula for connections between loss, complex skills and scaling factor, then we have result: the performance curve inferred by our method for k’-tuples of skills after scaling up is identical to the curve inferred for individual skills without scaling up.\n2.4.1 Emergence for Simple Skills Figure 7:Created by Xiaolan Liu. Skill graph where Y is the subset of such text pieces where the model makes mistakes on cloze questions.\n[(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936) mentioned how do we set up the theory in his paper: Let Y be the subset of such text pieces where the model makes mistakes on cloze questions. Let’s say the model makes a mistake on a text-piece if the total prediction loss on all the cloze questions of that text-piece is at least 1/2. Say Y contains \\(\\theta\\) fraction of text-pieces. Note that we cannot confuse \\(\\theta\\) with the average excess cross-entropy loss for those text-pieces. We have N1 text pieces, \\(\\theta\\)N1 of them make mistakes. It is easy to think that \\(\\theta\\)N1 /N = \\(\\theta\\) is equal to excess cross-entropy loss. However, Theorem 2 below shows those two are not equal. You can find the reconstruction of the proof in **Appendix 3.2.** Theorem 2 : if the average excess cross-entropy loss for the text-pieces is δ we conclude Y consists of at most 2δ fraction of text pieces.\nWe have theorem 3 below (you can find the proof in Appendix 3.3) guarantees that for most skills s, the model does not have significant error on the task associated with it. Note: theorem will give minimum guaranteed performance, actual performance could exceed this.\nTheorem 3: Let \\(\\alpha\\),\\(\\beta\\),\\(\\theta\\) \u003e 0, \\(\\beta\\)\u003e 1,\\(\\alpha\\beta\\) \u003c 1,\\(\\theta\\) \u003c 1 satisfy: \\[\\text{H}(\\theta) + k \\theta \\left( \\text{H}(\\beta \\alpha) - \\beta \\alpha \\log \\frac{1}{\\alpha} - (1-\\beta \\alpha) \\log \\left( \\frac{1}{1-\\alpha} \\right) \\right) = 0\\] where \\({H}(\\theta)\\) is Entropy defined as follows: \\[\\text{H}(x) = x \\log_2 \\frac{1}{x} + (1-x) \\log_2 \\frac{1}{1-x} \\tag{1}\\] We have the performance curve satisfying the theorem 3 as follows:\nFigure 8:see (Sanjeev et al. 2023). Performance Curves: The plot has theta = 0.1 and varies k = 2, 4, 8, 16. Higher values of k greatly improve performance.\nThe curve\\((k, \\theta)\\) above = set of \\((1-\\alpha,\\beta \\theta)\\) s.t. when excess c-e=\\(\\theta\\) then for \\(\\geq (1-\\alpha)\\) fraction of skills the model has error \\(\\leq \\beta \\theta\\) on the statistical task associated with that skill. For example, if \\(\\theta = 0.1\\), \\(\\alpha = 0.2\\), \\(\\beta = 3\\) \\(\\Rightarrow\\) For at least \\(1 - 0.2 = 0.8\\) fractions of skills, model answers incorrectly in at most 0.3 fraction of text pieces that used the skill. When we fix \\(\\theta\\), the emergence curves shift down noticeably (i.e., imply emergence of more skills) as we increase k. Note: please do not confuse k and k'. For simple skills, k means the number of simple skills that are required for generating text pieces. For complex skills, k also means the number of simple skills that are required for generating text pieces, but we have k' means the number of simple skills composed into complex skills. e.g., the perfromance curve shifts down if we increase the number of simple skills that are required for generating text pieces. But the performance curve shifts up(means more loss) for more complex skills(means bigger k’), see performance curve in 2.4.2.\nFigure 9: see (Sanjeev et al. 2023). Performance Curves: The plot has k = 8 and varies theta = 0.05, 0.1, 0.2.\nIf we fix k, when the model is scaled up, \\(\\theta\\) will go down, and the set Y containing erroneous answers on cloze questions will shrink. In terms of the emergence phenomenon, this corresponds to first signs of improvement of performance on tasks. 2.4.2 Emergence for Complex Skills We now derive emergence for tasks invloving complex (k’-tuples) skills. We have corollary 4 as follows:\nCorollary 4:In the same setting as Theorem 3 above,for integer \\(k' \\in [2, 1/\\theta]\\) the conclusion of that theorem holds also for \\(\\alpha, \\beta\\) pairs satisfying \\[\\text{H}(k'\\theta) + kk'\\theta \\left( \\text{H}(\\beta\\alpha) - \\beta\\alpha \\log \\frac{1}{\\alpha} - (1-\\beta\\alpha) \\log \\left( \\frac{1}{1-\\alpha} \\right) \\right) \u003c 0\\] Furthermore, if \\(\\text{H}(k'\\theta) \u003c k'\\text{H}(\\theta)\\) the emergence curve from this expression dominates that derived from Theorem 3 above. Figure 10: see (Sanjeev et al. 2023). Performance curve for t-tuples of skills for for theta = 0.05 and t = 1, 2, 4 respectively.\nBy the illustration in [(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936): From corollary 4, we can conclude that if \\(k'\\theta\\) is fixed, then we have same performance curve. It implies that the effect of reducing \\(\\theta\\) by a factor 2 has the effect of raising competence on 2k'-tuples to at least the same level as what it was on k'-tuples before reducing \\(\\theta\\). But how do we connect this with scaling law?\nBy the illustration in [(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936): Assume (for simplicity) a Chinchilla-like scaling law that 10x up-scaling leads to factor 2 reduction in excess entropy. By theorem 2, we know \\(\\theta\\) is proportional to excess cross entropy. So factor 2 reduction in \\(\\theta\\) corresponds factor 2 reduction in excess entrop. By the illustration in [(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936): If a model is considered to have reasonable performance on individual skill (1-tuple skills) at current scaling, then after further up-scaling of 10x(factor 2 reduction in \\(\\theta\\)) one would see similar reasonable performance on skill-pairs (2-tuples of skills), and scaling up by yet another 10x after that will yield similar reasonable performance on 4-tuples of skills, etc. Thus we have the result: the performance curve inferred by our method for k’-tuples of skills after scaling up is identical to the curve inferred for individual skills without scaling up. That means the competence of complex skills after scaling is not that samll, which means complex skills that were not seen during training must emerge.\nThe result is formalized as corollary 5 below: You can find the proof is in the paper.\nCorollary 5: When the model M1 with loss \\(\\delta\\) is scaled up (e.g., as per equation (3)) so that the new model M2 has loss \\(\\delta\\)/k', then the performance curve inferred by our method for k'-tuples of skills using M2 is identical to the curve inferred for individual skills on model M1. 2.4.3 Emergence analysis with general measure on text and skills Figure 11:Created by Xiaolan Liu. Skill graph where text pieces contain multiple skill clusters.\nMany skill clusters, not just one Each cluster has similar description as before, except skills of one cluster could be present in text in another cluster (e.g., ”Basic English” needed in ”Logic”)\nNothing much changes in theory, except now it only predicts emergence within a cluster if/when excess loss in that cluster goes down significantly.\nPart 3: Appendix 3.1 Theorem 1 If a model’s excess entropy at the ith place in text is ϵ then there is a cloze question with binary answer such that the probability that the model answers it incorrectly is at most \\(\\sqrt{2 \\epsilon}\\). Proof:\nDefine \\( p_i \\) to be the human's probability for the \\((i+1)\\)-th word, \\( q_i = \\) model's probability for the \\((i+1)\\)-th word. Step 1:\nShow that the probability of \\( p_i \\) and \\( q_i \\) giving different answers is \\( \\max_A \\left| \\sum_{A} \\left( p_i(w) - q_i(w) \\right) \\right| \\), where \\( A \\) is any subset of words. Pf of Step 1: Note that the human's probability \\( p_i \\) on \\((i+1)\\)-th word is: \\[ p_i(w) = P(W_{i+1} = w) = \\begin{cases} 1, \u0026 \\text{if } w = w^* \\\\ 0, \u0026 \\text{otherwise} \\end{cases} \\] i.e., \\( p_i(w^*) = 1 \\), \\( P_i(w) = 0 \\) if \\( w \\neq w^* \\) So \\( p_i \\) will always answer \\( w^* \\). The answer for \\( q_i(\\cdot) \\) is \\( \\arg \\max_w q_i(w) \\), denoted as \\( w^{**} \\). So in order to give different answers between \\( p_i \\) and \\( q_i \\), we need \\( w^* \\neq w^{**} \\). Step 2:\nFrom Step 1: $$ P(p_i \\text{ and } q_i \\text{ give different answers}) = \\text{variation distance between } p_i \\text{ and } g_i $$\nUsing Pinsker’s Theorem: $$ \\leq \\sqrt{\\frac{1}{2} KL(p_i \\Vert q_i)} \\leq \\sqrt{\\frac{1}{2} \\epsilon} $$\nConstruct the cloze question as follows:\nDefine \\(A_{i+1}\\) as: $$ A_{i+1} = \\arg \\max_A \\left| \\sum_A (p_i(w) - q_i(w)) \\right| $$ Then, the cloze question is: Is the \\((i+1)\\)-th word \\(w^*\\) in \\((a)\\), \\(A_{i+1}\\), or \\((b)\\), in \\(A_{i+1}^c\\)? $$ \\text{Pr(answer to cloze question is wrong)} = P(w^* \\in A_{i+1} \\text{ but we answer } (b)) + P(w^* \\in A_{i+1}^c \\text{ but we answer } (a)) $$\n$$ = P(p_i’s \\text{ answer is in } A_{i+1}, q_i’s \\text{ answer is in } A_{i+1}^c) + P(p_i’s \\text{ answer is in } A_{i+1}^c, q_i’s \\text{ answer is in } A_{i+1}) $$\n$$ \\leq P(p_i’s \\text{ answer is different from } q_i) + P(p_i’s \\text{ answer is different from } q_i) $$\n$$ = 2 P(p_i’s \\text{ answer is different from } q_i) $$\nIf we denote \\(p_i's \\text{ answer is in } A_{i+1}, q_i's \\text{ answer is in } A_{i+1}^c\\) as \\(E\\), \\(p_i's \\text{ answer is in } A_{i+1}^c, q_i's \\text{ answer is in } A_{i+1}\\) as \\(F\\), \\(p_i's \\text{ answer is different from } q_i\\) as \\(G\\). Since both \\(E\\) and \\(F\\) are subsets of \\(G\\), if \\(p_i's\\) answer in \\(A_{i+1}\\), \\(q_i's\\) answer in \\(A_{i+1}^c\\). Obviously answers are different, $$ \\Rightarrow E \\subseteq G, \\ F \\subseteq G $$\nThen by Pinsker’s Theorem above:\n$$ \\Rightarrow 2 \\cdot \\sqrt{\\frac{1}{2} \\epsilon} = \\sqrt{2 \\epsilon} $$\n3.2 Theorem2 Theorem 2 : if the average excess cross-entropy loss for the text-pieces is δ we conclude Y consists of at most 2δ fraction of text pieces.\nProof:\nAssume there are \\( N \\) text pieces, each text piece has \\( Q_i \\) cloze questions. \\( \\delta \\) is the average ce loss. \\[ \\delta = \\frac{1}{N} \\sum_{i=1}^N \\text{cross entropy on text piece } i \\] Since the ce loss on the text piece = the ce loss of cloze questions on this text piece,\n\\[ \\Rightarrow \\delta= \\frac{1}{N} \\sum_{i=1}^N \\frac{1}{Q_i} \\sum_{j=1}^{Q_i} \\text{cross entropy on cloze question } z_j^{(i)} \\] Since The average ce loss \\(\\geq\\) the loss in subset \\(Y\\). \\[ \\Rightarrow \\delta \\geq \\frac{1}{N} \\sum_{i \\in Y} \\frac{1}{Q_i} \\sum_{j=1}^{Q_i} \\text{cross entropy on cloze question } z_j^{(i)} := A_i \\] Step 1: Prove that \\( A_i \\geq \\frac{1}{2} \\) Step 2: Prove that \\( \\theta \\leq 2\\delta \\) Pf of step 1:\n\\[ A_i = \\frac{1}{Q_i} \\sum_{j=1}^{Q_i} \\text{cross entropy on cloze question } z_j^{(i)} \\] \\[ = \\frac{1}{Q_i} \\sum_{j=1}^{Q_i} \\sum_w -p_i(w) \\log q_i(w) \\] where \\(w\\) is all of the possible answers. \\[ = \\frac{1}{Q_i} \\left( \\sum_{j=1}^{Q_i} \\sum_w -p_i(w) \\log q_i(w) \\text{ (model is correct on } z_j^{(i)}) + \\sum_{j=1}^{Q_i} \\sum_w -p_i(w) \\log q_i(w) \\text{ (model is wrong on } z_j^{(i)})\\right) \\] \\[ \\geq \\frac{1}{Q_i} \\sum_{j=1}^{Q_i} \\sum_w -p_i(w) \\log q_i(w)\\text{ (model is wrong on } z_j^{(i)}) \\] Assume \\(w*\\) is the correct answer. \\(\\Rightarrow p_i(w^*) = 1, p_i(w) = 0 \\text{ if } w \\ne w^*\\) \\[ \\Rightarrow \\frac{1}{Q_i} \\sum_{j=1}^{Q_i} -\\log q_i(w^*) \\text{ (model is wrong on } z_j^{(i)}) \\] \\(\\text{Since model is wrong on } z_j^{(i)}\\) \\[ \\Rightarrow -\\log q_i(w^*) \\leq 1 \\quad (\\text{otherwise model will be correct}) \\] \\[ \\Rightarrow -\\log q_i(w^*) \\geq 1 \\] \\[ \\Rightarrow A_i = \\frac{1}{Q_i} \\sum_{j=1}^{Q_i} \\left( -\\log q_i(w^*) \\right)\\text{(model is wrong on } z_j^{(i)}) \\] \\[ \\geq \\frac{1}{Q_i} \\sum_{j=1}^{Q_i} 1 \\text{(model is wrong on } z_j^{(i)}) \\] Define set \\( S_i = \\{z_j^{(i)} : \\text{model is wrong on } z_j^{(i)}\\} \\) Since \\(Y\\) is the set of text pieces with each has at least half of wrong cloze questions on it. \\[ \\text{by definition } \\Rightarrow |S_i| \\geq \\frac{1}{2} |Q_i| \\] \\[ \\Rightarrow A_i \\geq \\frac{1}{Q_i} |S_i| \\geq \\frac{1}{2} \\] Pf of step 2:\nSince \\( \\delta \\geq \\frac{1}{N} \\sum_{i \\in Y} A_i \\) \\[ \\geq \\frac{1}{N} \\sum_{i \\in Y} \\frac{1}{2} \\quad (\\text{from step 1, } A_i \\geq \\frac{1}{2}) \\] \\[ = \\frac{1}{2N} |Y| \\] \\[ = \\frac{1}{2N} \\cdot \\theta N \\] \\[ \\Rightarrow \\theta \\leq 2 \\delta \\] 3.3 Theorem 3 Theorem 3: Let \\(\\alpha\\),\\(\\beta\\),\\(\\theta\\) \u003e 0, \\(\\beta\\)\u003e 1,\\(\\alpha\\beta\\) \u003c 1,\\(\\theta\\) \u003c 1 satisfy: \\[\\text{H}(\\theta) + k \\theta \\left( \\text{H}(\\beta \\alpha) - \\beta \\alpha \\log \\frac{1}{\\alpha} - (1-\\beta \\alpha) \\log \\left( \\frac{1}{1-\\alpha} \\right) \\right) = 0\\] where \\({H}(\\theta)\\) is Entropy defined as follows: \\[\\text{H}(x) = x \\log_2 \\frac{1}{x} + (1-x) \\log_2 \\frac{1}{1-x} \\tag{1}\\] Proof:\nWe say model makes a mistake in a text piece if it fails to answer \u003e= half of its cloze questions.\nSuppose \\(V1\\) is the set for text pieces and \\(V2\\) is the set for skills. Suppose \\(Y \\subseteq V1\\) of size \\(\\theta N1\\) is the subset of text pieces where model makes mistakes. We need to show that thare are at least \\((1-\\alpha)\\) fraction of vertices in \\(V2\\) each of which has at most \\(\\beta \\theta D\\) edges going to Y, where \\(D=\\frac{kN1}{N2}\\). Define a skill to be \"good\" if it has at most \\(\\beta\\theta D\\) edges going to Y, and \"bad\" if it has more than \\(\\beta\\theta D\\) edges going to Y. So we need to show that there are at least \\((1 - \\alpha) N2\\) good skills, or equivalently, show that there are at most \\(\\alpha N2\\) fraction bad skills. Define \\(Z \\subseteq V2, |Z2| \\leq \\alpha N2\\) be the subset of \\(V2\\) such that \\(Z\\) has at least \\(\\alpha \\beta \\theta kN1\\) edges to \\(Y\\). So \\(Z\\) is potentially the set for all \"bad\" skills. (Since \\((\\beta \\theta D) * (\\alpha N2) = \\alpha \\beta \\theta kN1)\\). If we can show that the expected number of such \\(Z\\)s is at most 1, then we can conclude the theorem because we have at most 1 such bad subset of skills, each has at most \\(\\alpha N2\\) bad skills, making it total at most \\(\\alpha N2\\) bad skills in \\(V2\\). By some combinatorics we conclude that the expected number of such \\(Z\\)s can be upper bounded by $$ N1N2\\binom{N2}{\\alpha N2}\\times \\binom{N1}{\\theta N1} \\times \\binom{k\\theta N_1}{\\beta \\alpha k \\theta N_1} \\times\\alpha^{\\beta\\alpha\\theta kN_1}\\times (1-\\alpha)^{(1-\\beta\\alpha)\\theta k N_1} $$ Note that the latter three terms is the probability in binomial distribution that among total \\(k\\theta N_1\\)outgoing edges from \\(Y\\), the probability of \\(\\beta \\alpha k\\theta N_1\\) of them connect to the vertices in Z. We need to show that the above formula can be upper bounded by 1, which can be shown by showing that the log of above is negative. Part 4: reference (Sanjeev et al. 2023)\n(Anderson, 1972)\n(Wei et al. 2022)\n(Schaeffer et al. 2023)\n(Lu et al. 2023)\n","wordCount":"6354","inLanguage":"en","image":"https://XIAOLAN-design.github.io/images/papermod-cover.png","datePublished":"2024-07-05T00:00:00Z","dateModified":"2024-07-05T00:00:00Z","author":{"@type":"Person","name":"Xiaolan Liu (Supervised by Prof Suvrit Sra)"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://XIAOLAN-design.github.io/posts/emergence/"},"publisher":{"@type":"Organization","name":"霄岚侠客","logo":{"@type":"ImageObject","url":"https://XIAOLAN-design.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://XIAOLAN-design.github.io/ accesskey=h title="霄岚侠客 (Alt + H)">霄岚侠客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://XIAOLAN-design.github.io/fr/ title=French aria-label=:fr:>🇫🇷</a></li><li><a href=https://XIAOLAN-design.github.io/fa/ title=Fa aria-label=Fa>Fa</a></li></ul></div></div><ul id=menu><li><a href=https://XIAOLAN-design.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://XIAOLAN-design.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://XIAOLAN-design.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/adityatelange/hugo-PaperMod/wiki/ title=WiKi><span>WiKi</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Emergence of Complex Skills in Language Model</h1><div class=post-description>Deep Exploration of Theory on Emergence of Large Language Model</div><div class=post-meta><span title='2024-07-05 00:00:00 +0000 UTC'>July 5, 2024</span>&nbsp;·&nbsp;30 min&nbsp;·&nbsp;Xiaolan Liu (Supervised by Prof Suvrit Sra)&nbsp;|&nbsp;<a href=https://github.com/adityatelange/hugo-PaperMod/tree/exampleSite/content/posts/emergence.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#part-1-discussion-of-emergence aria-label="Part 1: Discussion of Emergence">Part 1: Discussion of Emergence</a><ul><li><a href=#1-real-defintion-of-emergence aria-label="1 Real Defintion of Emergence">1 Real Defintion of Emergence</a><ul><li><a href=#11-outdated-definition-of-emergence aria-label="1.1 Outdated Definition of Emergence">1.1 Outdated Definition of Emergence</a></li><li><a href=#12-is-emergence-a-mirage aria-label="1.2 Is Emergence a Mirage?">1.2 Is Emergence a Mirage?</a></li><li><a href=#13-latest-defition-of-emergence aria-label="1.3 Latest Defition of Emergence">1.3 Latest Defition of Emergence</a></li></ul></li></ul></li><li><a href=#part-2-theory-of-emergence-of-complex-skills-in-language-model aria-label="Part 2: theory of emergence of complex skills in language model">Part 2: theory of emergence of complex skills in language model</a><ul><li><a href=#21-skills-of-language-moldels aria-label="2.1 Skills of Language Moldels">2.1 Skills of Language Moldels</a><ul><li><a href=#211-text-pieces aria-label="2.1.1 Text Pieces">2.1.1 Text Pieces</a></li><li><a href=#212-skills aria-label="2.1.2 Skills">2.1.2 Skills</a></li></ul></li><li><a href=#22-cross-entropy-loss-to-scaling-law aria-label="2.2 Cross Entropy Loss to Scaling Law">2.2 Cross Entropy Loss to Scaling Law</a><ul><li><a href=#221-cross-enrtopy aria-label="2.2.1 Cross Enrtopy">2.2.1 Cross Enrtopy</a></li><li><a href=#222-scaling-law aria-label="2.2.2 Scaling Law">2.2.2 Scaling Law</a></li><li><a href=#223-understanding-the-scaling-law-in-terms-of-excess-entropy aria-label="2.2.3 Understanding the Scaling Law in terms of excess entropy">2.2.3 Understanding the Scaling Law in terms of excess entropy</a></li></ul></li><li><a href=#23-skills-modelling aria-label="2.3 Skills modelling">2.3 Skills modelling</a><ul><li><a href=#231-mixing-assumption aria-label="2.3.1 Mixing Assumption">2.3.1 Mixing Assumption</a></li><li><a href=#232-scaling-law-assumption aria-label="2.3.2 Scaling law Assumption">2.3.2 Scaling law Assumption</a></li><li><a href=#233-cloze-sufficiency-assumption aria-label="2.3.3 Cloze Sufficiency Assumption">2.3.3 Cloze Sufficiency Assumption</a></li><li><a href=#234-compentence-on-the-skills aria-label="2.3.4 compentence on the skills">2.3.4 compentence on the skills</a></li></ul></li><li><a href=#24--analysis-of-emergence aria-label="2.4  Analysis of Emergence">2.4 Analysis of Emergence</a><ul><li><a href=#241-emergence-for-simple-skills aria-label="2.4.1 Emergence for Simple Skills">2.4.1 Emergence for Simple Skills</a></li><li><a href=#242-emergence-for-complex-skills aria-label="2.4.2 Emergence for Complex Skills">2.4.2 Emergence for Complex Skills</a></li><li><a href=#243-emergence-analysis-with-general-measure-on-text-and-skills aria-label="2.4.3 Emergence analysis with general measure on text and skills">2.4.3 Emergence analysis with general measure on text and skills</a></li></ul></li></ul></li><li><a href=#part-3-appendix aria-label="Part 3: Appendix">Part 3: Appendix</a><ul><li><a href=#31-theorem-1 aria-label="3.1 Theorem 1">3.1 Theorem 1</a></li><li><a href=#32-theorem2 aria-label="3.2 Theorem2">3.2 Theorem2</a></li><li><a href=#33-theorem-3 aria-label="3.3 Theorem 3">3.3 Theorem 3</a></li></ul></li><li><a href=#part-4-reference aria-label="Part 4: reference">Part 4: reference</a></li></ul></div></details></div><div class=post-content><p>This Blog is devided into 2 parts. First part is the review of discussion of Emergence. You can just skip part 2 if you are not interested in theoretical staff. Second part illustrates the theory of emergence of complex skills in language model in a way people can understand easily, which is based on <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a> and the modified version of the paper Prof Arora (the author of the paper) sent me. Many thanks for the modified version of the paper and his comments on this blog.</p><p>The motivation for this blog is to make the relating theory easy for people to understand, so I put more illustration work on this blog but not omit some important theoretical staff. All of the formal definitions, assumptions and theorems in this paper are from those two resources above and other relating papers that I will refer later.</p><p>The first contribution is that I explained a few concepts in the paper in more detail. For example, in the 1st part of the blog, I gave a full review about what is emergence and what is the emergence of complex skills which the authors didn&rsquo;t explain well. In the 2nd part, I wrote down the intuitions of the main theorems and how they were connected to the LLM which was not covered in the original paper.</p><p>The second contribution is that I added the proofs of a few statements which the author skipped in his paper (see Appendix 3.1, 3.2). I also reconstructed the proof of some theorems in a simpler way(see Appendix 3.3).</p><p>Considering the paper <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a> is not finalized, thus this blog cannot be yet finalized,too. I will keep it updated once I recieved more information from Professor Arora.</p><hr><h1 id=part-1-discussion-of-emergence>Part 1: Discussion of Emergence<a hidden class=anchor aria-hidden=true href=#part-1-discussion-of-emergence>#</a></h1><p>The exsitance of emergence has been a hated topic recently. The debate mainly comes from different definition of emergence, thus we will review all of the definitions in the following.</p><h2 id=1-real-defintion-of-emergence>1 Real Defintion of Emergence<a hidden class=anchor aria-hidden=true href=#1-real-defintion-of-emergence>#</a></h2><p>Emergence is a popular phenomena in domains such as physics, biology, etc. The general definition of emergence, adapted from Steinhardt (2022) and
rooted in a 1972 essay called “More Is Different” by Nobel prize-winning physicist Philip Anderson <a href=http://www.lanais.famaf.unc.edu.ar/cursos/em/Anderson-MoreDifferent-1972.pdf>(Anderson, 1972)</a>:</p><blockquote><ul><li>Quantitative changes in a system result in qualitative changes in behavior.</li></ul></blockquote><p>The <strong>emergent abilities</strong> of large language models also attract lots of attention recentlly. However, the official definition of Emergence of Language Models remains in hated discussion.</p><h3 id=11-outdated-definition-of-emergence>1.1 Outdated Definition of Emergence<a hidden class=anchor aria-hidden=true href=#11-outdated-definition-of-emergence>#</a></h3><p><a href=https://arxiv.org/pdf/2206.07682>(Wei et al. 2022)</a> first introduced emergent abilities of large language models, it was defined as following:</p><blockquote><ul><li><strong>Sharpness, transitioning</strong> seemingly instantaneously from
not present to present.</li><li><strong>Unpredictability</strong>, transitioning at seemingly unforeseeable
model scales</li></ul></blockquote><figure><img loading=lazy src=/images/my_post_folder/emergence_transition.png alt="Scenario 1: Across columns"><figcaption><p>Figure 1: see <a href=https://arxiv.org/pdf/2206.07682>(Wei et al. 2022)</a>. Eight examples of emergence in the few-shot prompting setting. Each point is a separate model. The ability to perform a task via few-shot prompting is emergent when a language model achieves random performance until a certain scale, after which performance significantly increases to well-above random.</p></figcaption></figure><figure><img loading=lazy src=/images/my_post_folder/emergence_transition2.png alt="Scenario 1: Across columns"><figcaption><p>Figure 2:see <a href=https://arxiv.org/pdf/2206.07682>(Wei et al. 2022)</a>. Analogous figure with number of model parameters instead of training flops in figure 1. Obviously it shows Figure 1 and figure 2 have the exactly same performance, which means models that used more training compute also typically have more parameters—hence.</p></figcaption></figure><h3 id=12-is-emergence-a-mirage>1.2 Is Emergence a Mirage?<a hidden class=anchor aria-hidden=true href=#12-is-emergence-a-mirage>#</a></h3><p>However, there was a time that people both from industry and academia doubted the <strong>existance of Emergent Abilities</strong> for language models. They argued those models actually do not show <code>Sharpness</code>,<code>transitioning</code>, <code>unpredictability</code> performance improvement when the model is scaled up, thus do not have Emergent Abilities.</p><p>There is no doubt the model gets better performance with more <code>number of parameters</code> and <code>training flops</code>.</p><ul><li>But is the better performance just the sum of small improvement of each scaling up stage or is it greater than sum of those?</li><li>Whether the sharp transition of the performance curve come from the choice of evaluation of metrics? see more in <a href=https://hai.stanford.edu/news/ais-ostensible-emergent-abilities-are-mirage>(Emergent Abilities Are a Mirage)</a></li></ul><figure><img loading=lazy src=/images/my_post_folder/emergence_slow.png alt="Scenario 1: Across columns"><figcaption><p>Figure 3:see <a href=https://arxiv.org/pdf/2304.15004>(Schaeffer et al. 2023)</a>. Claimed emergent abilities evaporate upon changing the metric. Left to Right: Mathematical Model, 2-Integer 2-Digit Multiplication Task, 2-Integer 4-Digit Addition Task. Top: When performance is measured by a nonlinear metric (e.g., Accuracy), the InstructGPT/GPT-3 [3, 24] family’s performance appears sharp and unpredictable on longer target lengths. Bottom: When performance is instead measured by a linear metric (e.g., Token Edit Distance), the family exhibits smooth, predictable performance improvements.</p></figcaption></figure><p><a href=https://arxiv.org/pdf/2304.15004>(Schaeffer et al. 2023)</a> conducted lots of experiments to prove that the sharpness, transitioning and unpredictability performance improvment of large language model is a creation of <strong>chosen metrics</strong>. Typically, linear or continuous metrics produce <code>smooth</code>,<code>continuous</code>,<code>predictable</code> changes in model performance, while a nonlinear or discontinuous metric can distort the model family’s performance from continuous, predictable changes to appear sharp, unpredictable.</p><p>However, the explanation of metric choice above cannot be the evidence to deny the exsitance of emergent abilities. Since eventhough the performance does not show sharp transitioning, the improvement is still unpredictable to some extent.</p><ul><li><p>As picture above shows, the performance improvement does not follow a deterministic function of scaling , which means it is unpredictable.</p></li><li><p>Also, the increasing rate of performance improvement is getting bigger and bigger, which means <code>the performance improvement is greater than sum of small improvement of each scaling up stage,</code> which obviously support that new skills will be emergent in large models.</p></li></ul><h3 id=13-latest-defition-of-emergence>1.3 Latest Defition of Emergence<a hidden class=anchor aria-hidden=true href=#13-latest-defition-of-emergence>#</a></h3><p>Slow emergence is more widely accepted recently, meaning that the performance curve does not have to appear as a sharp transition when the model is scaled up. The sharp transition might be due to the <strong>final step metric evaluation</strong> method we used for meausring model performance. That is: solving one task reguires several steps, the models performance is actually incresing in each scaling step. but the evaluation metric just count for final step, which will result in the sharp transition of performance curve.</p><p>Emergence is firstly introduced as <strong>Slow Emergence</strong> by <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a>, which is defined as follows:</p><blockquote><ul><li>As number of sample sizes and number of parameters increase together then the model’s performance on a broad range of language tasks improves in a correlated way.</li></ul></blockquote><p>I personally do not totally agree with the definition above. I agree that the performance curve does not have to be sharp transition part, but the performance increasement should be <strong>1+1>2</strong>, which means <strong>the better performance is not the sum of small improvement of each scaling up stage, it should be greater than sum of those.</strong> however, the definition above does not illustrate 1+1>2.</p><p><strong>In the paper by <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a>, emergence of simple skills is defined as slow emergence above. Emergence of complex skills is defined as something new (those were not seen during training means new things) emerge</strong></p><p>There are further discussion about emergence, <a href=https://arxiv.org/pdf/2309.01809>(Lu et al. 2023)</a> firstly mentioned Emergent abilities are <strong>In-context Learning</strong>. At the moment I will not extend this part.</p><hr><h1 id=part-2-theory-of-emergence-of-complex-skills-in-language-model>Part 2: theory of emergence of complex skills in language model<a hidden class=anchor aria-hidden=true href=#part-2-theory-of-emergence-of-complex-skills-in-language-model>#</a></h1><p>I will first give a <strong>intuition</strong> about why complex skills emerge in language models. We have a text corpus, the the size of the training corpus is almost same with number of simple skills. We define complex skill as k&rsquo;-tuple skill, which is composed of k&rsquo; simple skills (you can find details about definitions about corpus and skills below).</p><p>Assume we have 1000 training size and 1000 simple skills, 5 simple skills(k'=5) can compose a complex skill, thus we have \(1000^{5}\) =\(10^{15}\)combinations of complex skills. Since the training size is 1000, it can only see 1000/\(10^{15}\)=1/\(10^{12}\) proportion of complex skills during training(learning).<p>We know that the model can only learn seen skills, if the model can only see 1/\(10^{12}\) proportion of complex skills during training, then it displays competence on complex skills is at most 1/\(10^{12}\) proportion. Thus if the model can display competency on even 10% proportion, which means the model emerges 10%-1/\(10^{12}\) complex skills despite it has never learned(seen during training) those complex skills.<p>Thus, in order to show the emergence of complex skills, we need to show the competence of complex skills is at least not too small (bigger than e.g. 1/\(10^{12}\)), which means lots of new complex skills that are not seen during training process emerge.<p>Here we introduce competence of simple skills to help us to quantify the competence of complex skills. <strong>If we can show that the competence of complex skill after scaling is at least the same level of competence of simple skills</strong>, which means the competence of complex skills is at least not too small since the competence of simple skills is not too small(since each simple skill will be seen thus be learned during training, so the competence of simple skills are not small).</p><blockquote><p><strong>So in part 2, the main goal is to quantify the competence of skills, then connect competence, scaling law and loss together to show that the competence of complex skill after scaling is at least the same level of competence of simple skills. Thus with the competence of complex skill bigger than the proportion of complex skills will be seen during training, we can conclude that the model can emerge new complex skills that are not seen during training when scaling up.</strong></p></blockquote><p>The structure of part 2 is as follows: we firstly introduce some basic knowledge for analyzing emergence in 2.1, 2.2 and 2.3. Then based on these, in 2.4.1 we analyze slow emergence(recall <strong>real definition of emergence</strong> in part 1) in language model from statistical view, which <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a> is as follows:</p><blockquote><p>As the model’s excess cross entropy goes down due to scaling, the model’s performance improves.</p></blockquote><p>Then in 2.4.2 we continue introducing <strong>how complex skills(k&rsquo; skills) emerge due to scaling</strong>, the key result as follows shows that if we scale up the model, the performance we get for complex skills is equal to performance we get for simple skills without scaling <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a>:</p><blockquote><p>If models of size S have a certain success rate (compentence) at solving tasks that require k&rsquo; skills, then Scaling Laws imply that scaling up models (i.e. to size 10S leads to factor 2 reduction in loss) will give them the same success rate on tasks that involve combining 2k&rsquo; skills as what we get on k&rsquo; skills.</p></blockquote><h2 id=21-skills-of-language-moldels>2.1 Skills of Language Moldels<a hidden class=anchor aria-hidden=true href=#21-skills-of-language-moldels>#</a></h2><p>First, we will clarify some terminologies required for this theory. There is no official definition for Skills of Language Model. Generally speaking, for those words generated by humanbeings or by neural network models, some skills are applied. <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a> develped a new theory as follows to describe skills as those for generating text pieces.</p><h3 id=211-text-pieces>2.1.1 Text Pieces<a hidden class=anchor aria-hidden=true href=#211-text-pieces>#</a></h3><p><strong>Definition of Text Piece:</strong> <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a></p><blockquote><ul><li></p>There is a measure \(µ_{2}()\) on these text-pieces, with \(µ_{2}(t)\) denoting the measure of text-piece t. The usual cross-entropy loss is computed by weighting text-pieces with respect to this measure.</li></ul></blockquote><p>Assume we choose one piece of news from NewYork Times as our corpus, text piece should be thought of as having a size between a paragraph to a few pages, drawn from a longer corpus. Equivalently speaking, we can divide the news into text-pieces, each text pieces consitsts \(C\) tokens. We have train process and test process, thus corpus is devided as train corpus and test corpus, respectively. We will see in scling law introduced later that only test corpus is considered in this theory.
--><h3 id=212-skills>2.1.2 Skills<a hidden class=anchor aria-hidden=true href=#212-skills>#</a></h3><p><strong>Definition of skill Graph:</strong> <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a></p><blockquote><ul><li></p>A skill graph is a bipartite graph \((V_{1}, V_{2}, E)\) where nodes in \(V_{2}\) correspond to skills, there is a measure \(µ_{1}()\) on these skills, with \(µ_{1}(s)\) denoting the measure of skill \(s\).</li></ul></blockquote><p><figure><img loading=lazy src=/images/my_post_folder/skill.jpg alt="Scenario 1: Across columns"><figcaption><p>Figure 4:see <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a>. Each text piece can be generated by applying several skills.</p></figcaption></figure>For each text piece, skills are required for generating it. For the sentence above, What kinds of skills could it apply to generate the text pieces? You will have the answer after getting to know what do skills mean.
We have example of skills as follows.</p><ul><li>Named Entity Recognition (NER)</li><li>pronoun disambiguation</li><li>Sentiment Analysis</li><li>Anaphora Resolution</li><li>Logical Inference</li><li>World Knowledge</li></ul><blockquote><ol><li>Barack Obama was born in Hawaii. He served as the 44th President of the United States.</li></ol></blockquote><p>For the sentence above, <code>Barack Obama</code> is a name, <code>Hawaii</code> is a location, and <code>the United States</code> is a country, all of which can be determined by the skill <strong>Named Entity Recognition (NER)</strong>. And by applying <strong>pronoun disambiguation</strong> can we infer <code>He</code> means <code>Barack Obama</code>.</p><blockquote><ol start=2><li>I love waiting in long lines. It makes me want to cut myself</li></ol></blockquote><p>The sentence above is bit hard since it is an ironical expression, the word <code>love</code> here is not really love, it means <code>hate</code> instead, which requires the skill <strong>entiment analysis</strong> to analyze the sentiment of this expression is negative by the negative verb <code>cut myself</code>.</p><blockquote><ol start=3><li>The CEO of the company made an announcement. It surprised everyone, so they get together to drink in the bar.</li></ol></blockquote><p><code>It</code> in the sentence means the thing <code>he CEO of the company made an announcement</code>, which requires the skill <strong>Anaphora Resolution</strong>. Since everyone is amazed by the god news, so we can infer everyone is happy, then they will celebrate in some place like in the bar, which requires the skill <strong>Logical Inference</strong>.</p><p>Though I just list several skills for one sentence, the truth is when we generate the sentence, we have to apply almost every skills we want. the skills above are those named by human. However, there are more skills that are not found or named by human beings. For instance, those are lots of skills used in large language models like GPT, we human however cannot know each specific skills the model applies to generate text.</p><p>After getting to know those examples above, a quick quiz for you: what kinds of skills could it apply to generate the following text pieces?</p><blockquote><p>The city councilmen refused the demonstrators a permit because they feared violence.</p></blockquote><hr><h2 id=22-cross-entropy-loss-to-scaling-law>2.2 Cross Entropy Loss to Scaling Law<a hidden class=anchor aria-hidden=true href=#22-cross-entropy-loss-to-scaling-law>#</a></h2><p>Since we want to connect scaling law with skills, we can choose cross entropy as our bridge. We first find connection between cross entropy and scaling law, then we find connection between cross entropy and skills, thus we can find connection between scaling law and skills. So in this part, we are gonna first intriduce <strong>cross entropy</strong> then <strong>scaling law</strong>, then we will find connection between them.</p><h3 id=221-cross-enrtopy>2.2.1 Cross Enrtopy<a hidden class=anchor aria-hidden=true href=#221-cross-enrtopy>#</a></h3><p>For word generation, we always have a sequence of previous words to generate the next word, which is also named as next word prediction. Similar to other predicting process, language generating process also has 2 probability. One is the probability of the next predicted word of the current model, the other is the ground-truth probability (i.e. humans' choice), which can be understood as the true label for next word prediction process.</p>Given the previous words \(w_1 w_2 \ldots w_i\), the probability distribution of the model itself \(q_{i}\left(w\right)\), which can be defined as \(\operatorname{q}_i\left[w \mid w_1 w_2 \ldots w_i\right]\).</p>The ground truth distribution \(p_{i}\left(w\right)\) for generating the next \((i + 1)th\) word \(w\), which is defined as \(\operatorname{p}_i\left[w \mid w_1 w_2 \ldots w_i\right]\).<p>$$
p_{i}\left(w\right)\ =
\begin{cases}
1, & \text{if } w = w_{i+1} \\
0. & \text{if} w\not =w_{i+1}
\end{cases}\quad (1)
$$</p>We take a particular interest in the difference between predicted word and the ground-truth word. The Cross Entropy can get a measure of dissimilarity between \(p_{i}\left(w\right)\) and \(q_{i}\left(w\right)\).Thus we introduce cross-entropy loss of the model on one word is:<p>$$
\sum_w p_i(w) \log \frac{1}{q_i(w)} \quad(\text {Cross Entropy of the word}) \quad (2)
$$
We have many attempts to make predictions, only one attempt is correct. That means only one attempt with ground-truth probability of 1, others are 0. So we sum all of the attempts (w) together to get the cross entropy on the ((i+1)th) word.</p><p>$$
\sum_w p_i(w_{i+1}) \log \frac{1}{q_i(w_{i+1})} = \log \frac{1}{q_i(w_{i+1})}\quad (3)
$$</p><p>It is easy to be confused between the Cross Entropy of the model and Cross Entropy of the word. Cross Entropy of the model is the total cross entropy of each word in the test corpus. After getting cross entropy of the word, we need to sum up all the cross entropy of the word to get the cross entropy of the model M.</p><p>$$
\ell(M)=\sum_{i=1}^{N} \log \frac{1}{q_i(w_{i+1})}
=-\sum_{i=1}^{N} \log q_i(w_{i+1}) \quad (4)
$$
which can be defined as follows:
$$
=-\sum_i \log \underset{M}{\operatorname{Pr}}\left[w_{i+1} \mid w_1 w_2 \ldots w_i\right] \quad \text { (Cross Entropy of the Model) } \quad (5)
$$</p></p>We are also interested in the inherent property of language, we know human can have lots of choices for making the next word. Entropy can be used to describe the "uncertainty" inherent to the variable's possible outcomes. Thus we use Entropy to descibe inherent uncertainty of one word prediction:</p>$$
\sum_w p_i(w) \log \frac{1}{p_i(w)} \quad(\text {Entropy}) \quad (6)
$$<p>We also introduce KL divergence, which quantifies the information loss when the predicted distribution \(q_{i}\left(w\right)\) is used to approximate the true distribution \(p_{i}\left(w\right)\). it is also sometimes called excess entropy, is non-negative and defined as:
$$
K L\left(p_i \| q_i\right)=\sum_w p_i(w) \log \frac{p_i(w)}{q_i(w)} \quad(\text {Excess Entropy}) \quad (7)
$$<p>Then we can find an intersting relationship on a per-word basis from equation\((1),(2)\) and \((3)\):
$$
\text { Corss Entropy }=\text { Entropy }+ \text { Excess Entropy} \quad (8)
$$<h3 id=222-scaling-law>2.2.2 Scaling Law<a hidden class=anchor aria-hidden=true href=#222-scaling-law>#</a></h3><p>Recall in part 1 we mentioned the real definition of Emergence:</p><blockquote><p>As number of sample sizes and number of parameters increase together then the model’s performance on a broad range of language tasks improves in a correlated way.</p></blockquote><p>The definition above reflects <strong>Scaling law</strong>, which describes how test cross entropy loss on test experiments scales with number of model parameters (N) and size of the dataset (D) Researchers have conducted lots of expiriments to derive Scaling law, Hoffmann et al. [2022] derived the scaling law is as follows:</p></p>$$
L(N, D) = A + \frac{B}{N^{0.34}} + \frac{C}{D^{0.28}} \quad A=1.61 \quad B=406.4 \quad C=410.7 \quad (9)
$$<h3 id=223-understanding-the-scaling-law-in-terms-of-excess-entropy>2.2.3 Understanding the Scaling Law in terms of excess entropy<a hidden class=anchor aria-hidden=true href=#223-understanding-the-scaling-law-in-terms-of-excess-entropy>#</a></h3></p>From [(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936), if we compare equation \((9)\) with \((8)\), the \(A\) term of \((9)\) captures the entropy of language. The lowest cross-entropy loss is entropy, that is term \(A\) for large corpora. The second and third terms of \((9)\) capture excess entropy, and they decrease polynomially with \(N\) and \(D\). For example when \(D\) is increased by a factor of 10 it reduces by roughly \(10^{0.28} \approx 2\).</p><p>This partly explains well the choice of metric evaluation could change the oerformance curve from sharp transition into slow increasement. As picture below shows: If we replace our loss metric from error rate as cross-entropy loss. We can observe the sharp transition of the perfromance curve disappear.</p></p>That is because the term \(A\) is a constant term, while the improvement of performance is brought by the sencond and third term. Thus, when there is some improvement for the sencond and third term, after we plus the first constant term \(A\), the curve will not show obvious improvement. Thus given the fact that excess cross entropy is the real driver in language generating process, it seems that we just need to consider **Excess Cross Entrioy** in our theory.<figure><img loading=lazy src=/images/my_post_folder/emergence_ce_loss.jpg alt="Scenario 1: Across columns"><figcaption><p>Figure 5:see <a href=https://arxiv.org/pdf/2304.15004>(Schaeffer et al. 2023)</a>. Adjacent plots for error rate, cross-entropy loss, and log probabilities of correct and incorrect responses on three classification tasks on BIG-Bench that we consider to demonstrate emergent abilities. Logical arguments only has 32 samples, which may contribute to noise. Error rate is (1 - accuracy).</p></figcaption></figure><hr><h2 id=23-skills-modelling>2.3 Skills modelling<a hidden class=anchor aria-hidden=true href=#23-skills-modelling>#</a></h2><p>Skill modelling is a process of finding relationship between <strong>excess cross entropy</strong> and <strong>compentence on the skills</strong>. First we will make some assumptions, then we can quantify the model’s competence on particular skill.</p><h3 id=231-mixing-assumption>2.3.1 Mixing Assumption<a hidden class=anchor aria-hidden=true href=#231-mixing-assumption>#</a></h3><blockquote><ul><li></p>Each text-piece \(t\) can be generated by picking \(k-tuple\) of skills iid from measure \(µ_{1}()\) sing an unknown process, which assigns probability \(µ_{2}(t)\).</li></ul></blockquote><figure><img loading=lazy src=/images/my_post_folder/skill_elementary.png alt="Scenario 1: Across columns"><figcaption><p>Figure 6:Created by Xiaolan Liu. Skill graph where each text-piece t can be generated by picking k−tuple of skills .</p></figcaption></figure><p>It is assumed that we have a set of skills, which is pretty large and bit smaller than the number of text-pieces text pieces. Then text pieces are generated by picking random k-tuples of skills. l</p><h3 id=232-scaling-law-assumption>2.3.2 Scaling law Assumption<a hidden class=anchor aria-hidden=true href=#232-scaling-law-assumption>#</a></h3><blockquote><ul><li>The theory will assume scaling laws such as (9), thus it can reason directly about the model’s behavior on the test distribution</li></ul></blockquote><p>We know the training corpus is quite large, which makes it hard to model our theory in training process. Luckily, the scaling laws help us avoid reasoning about training and generalization. The scaling law is based on test cross entropy loss, thus our theory does not need to refer to training cross entropy loss.</p><h3 id=233-cloze-sufficiency-assumption>2.3.3 Cloze Sufficiency Assumption<a hidden class=anchor aria-hidden=true href=#233-cloze-sufficiency-assumption>#</a></h3><blockquote><ul><li></p>To test the \(k\) underlying skills in \(t\), adds cloze prompts to \(t\) via an unknown process. The pre-trained model’s average prediction loss on Cloze questions (where the average is taken over the distribution of text pieces) closely tracks the excess cross-entropy of the model on classical next-word prediction.</p></li></ul></blockquote><p><strong>Theorem 1</strong> in <strong>Appendix 3.1</strong> justifies the exsitence of this assumption. You can find detailed math proof in Appendix.</p><p>The excess cross-entropy of the model on classical next-word prediction is not easy to calculate. Here we need to consider a equivalent method to get excess cross entropy loss, which is cloze questions approach. That means we add multiple choice question answering on text pieces to test the language model&rsquo;s ability of understanding. Think the example below mentioned in <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a></p><blockquote><p>The city councilmen refused the demonstrators a permit because they feared violence.</p></blockquote><p>Here the pronoun <code>they</code> is ambiguous— grammar rules allow it to refer to either <code>demonstrators</code> or <code>city councilmen</code>. To test the model’s understanding of they in this sentence, we can append a prompt:</p><p><code>Q. Who feared violence? A. city councilmen B.demonstrators</code></p><p>Assume there are \( N \) text pieces in our model, we add \( Q_i \) cloze questions on this text piece above. The prediction loss on the text-piece above is the cross-entropy loss on predicting the answers to the cloze questions in it. The average prediction loss over all text-pieces is computed with respect to the measure \(µ_{2}()\), if we assume measure \(µ_{2}()\) is uniform. Then we have the average prediction loss over all text-pieces, noted as \( \delta \), is defined as follows:<p>\[
\delta = \frac{1}{N} \sum_{i=1}^N \text{cross entropy on text piece } i
\]<p>\[
= \frac{1}{N} \sum_{i=1}^N \frac{1}{Q_i} \sum_{j=1}^{Q_i} \text{cross entropy on cloze question } z_j^{(i)}
\]<h3 id=234-compentence-on-the-skills>2.3.4 compentence on the skills<a hidden class=anchor aria-hidden=true href=#234-compentence-on-the-skills>#</a></h3><p>By cloze sufficiency assumption above, we replace model’s average prediction loss on Cloze questions as excess cross-entropy of the model on classical next-word prediction. Now we need to connect model’s average prediction loss on Cloze questions and compentence on the skills.</p><p>For a skill s, the competence of a model defined in the modified version of the paper Sanjeev sent to me: it is the expectation of the following random variable: randomly sample a text-piece containing that skill (this sampling uses the measure \(µ_{2}(·)\) on text-pieces) and measure the model’s success rate (1 - \( \delta \)) at answering cloze questions in that text piece. We similarly define Competence on a tuple of skills (s1,s2,...,).<hr><h2 id=24--analysis-of-emergence>2.4 Analysis of Emergence<a hidden class=anchor aria-hidden=true href=#24--analysis-of-emergence>#</a></h2><p>Now we have set up a framework for modeling skills and connecting skills to the cross-entropy loss of the model, we firstly derive a mathematical formula for connections between loss, <code>simple skills</code> and scaling factor, then we have result: <strong>As the model’s excess cross entropy goes down due to scaling, the model’s performance on cloze tasks improves.</strong></p><p>After that, we derive a mathematical formula for connections between loss, <code>complex skills</code> and scaling factor, then we have result: <strong>the performance curve inferred by our method for k&rsquo;-tuples of skills after scaling up is identical to the curve inferred for individual skills without scaling up.</strong></p><h3 id=241-emergence-for-simple-skills>2.4.1 Emergence for Simple Skills<a hidden class=anchor aria-hidden=true href=#241-emergence-for-simple-skills>#</a></h3><figure><img loading=lazy src=/images/my_post_folder/Y.jpg alt="Scenario 1: Across columns"><figcaption><p>Figure 7:Created by Xiaolan Liu. Skill graph where Y is the subset of such text pieces where the model makes mistakes on cloze questions.</p></figcaption></figure><p>[(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936) mentioned how do we set up the theory in his paper: Let Y be the subset of such text pieces where the model makes mistakes on cloze questions. Let’s say the model makes a mistake on a text-piece if the total prediction loss on all the cloze questions of that text-piece is at least 1/2. Say Y contains \(\theta\) fraction of text-pieces.<p>Note that we cannot confuse \(\theta\) with the average excess cross-entropy loss for those text-pieces. We have N1 text pieces, \(\theta\)N1 of them make mistakes. It is easy to think that \(\theta\)N1 /N = \(\theta\) is equal to excess cross-entropy loss. However, Theorem 2 below shows those two are not equal. You can find the reconstruction of the proof in **Appendix 3.2.**<blockquote><p><strong>Theorem 2</strong> : if the average excess cross-entropy loss for the text-pieces is δ we conclude Y consists of at most 2δ fraction of text pieces.</p></blockquote><p>We have <strong>theorem 3</strong> below (you can find the proof in <strong>Appendix 3.3</strong>) guarantees that for most skills s, the model does not have significant error on the task associated with it. Note: theorem will give minimum guaranteed performance, actual performance could exceed this.</p><blockquote><p>Theorem 3: Let \(\alpha\),\(\beta\),\(\theta\) > 0, \(\beta\)> 1,\(\alpha\beta\) < 1,\(\theta\) < 1 satisfy:<p>\[\text{H}(\theta) + k \theta \left( \text{H}(\beta \alpha) - \beta \alpha \log \frac{1}{\alpha} - (1-\beta \alpha) \log \left( \frac{1}{1-\alpha} \right) \right) = 0\]<p>where \({H}(\theta)\) is Entropy defined as follows:<p>\[\text{H}(x) = x \log_2 \frac{1}{x} + (1-x) \log_2 \frac{1}{1-x} \tag{1}\]</blockquote><p>We have the <strong>performance curve</strong> satisfying the theorem 3 as follows:</p><figure><img loading=lazy src=/images/my_post_folder/emergence_curve4.jpg alt="Scenario 1: Across columns"><figcaption><p>Figure 8:see <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a>. Performance Curves: The plot has theta = 0.1 and varies k = 2, 4, 8, 16. Higher values of k greatly improve performance.</p></figcaption></figure><p>The curve\((k, \theta)\) above = set of \((1-\alpha,\beta \theta)\) s.t. when excess c-e=\(\theta\)
then for \(\geq (1-\alpha)\) fraction of skills the model has error \(\leq \beta \theta\) on the statistical task associated with that skill. For example, if \(\theta = 0.1\), \(\alpha = 0.2\), \(\beta = 3\) \(\Rightarrow\) For at least \(1 - 0.2 = 0.8\) fractions of skills, model answers incorrectly in at most 0.3 fraction of text pieces that used the skill.<p>When we fix \(\theta\), the emergence curves shift down noticeably (i.e., imply emergence of more skills) as we increase k. Note: please do not confuse k and k'. For simple skills, k means the number of simple skills that are required for generating text pieces. For complex skills, k also means the number of simple skills that are required for generating text pieces, but we have k' means the number of simple skills composed into complex skills.<p>e.g., the perfromance curve shifts down if we increase the number of simple skills that are required for generating text pieces. But the performance curve shifts up(means more loss) for more complex skills(means bigger k&rsquo;), see performance curve in 2.4.2.</p><figure><img loading=lazy src=/images/my_post_folder/emergence_curve2.jpg alt="Scenario 1: Across columns"><figcaption><p>Figure 9: see <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a>. Performance Curves: The plot has k = 8 and varies theta = 0.05, 0.1, 0.2.</p></figcaption></figure><p>If we fix k, when the model is scaled up, \(\theta\) will go down, and the set Y containing erroneous answers on cloze questions will shrink. In terms of the emergence phenomenon, this corresponds to first signs of improvement of performance on tasks.<h3 id=242-emergence-for-complex-skills>2.4.2 Emergence for Complex Skills<a hidden class=anchor aria-hidden=true href=#242-emergence-for-complex-skills>#</a></h3><p>We now derive emergence for tasks invloving complex (k&rsquo;-tuples) skills. We have <strong>corollary 4</strong> as follows:</p><blockquote><p>Corollary 4:In the same setting as Theorem 3 above,for integer \(k' \in [2, 1/\theta]\) the conclusion of that theorem holds also for \(\alpha, \beta\) pairs satisfying<p>\[\text{H}(k'\theta) + kk'\theta \left( \text{H}(\beta\alpha) - \beta\alpha \log \frac{1}{\alpha} - (1-\beta\alpha) \log \left( \frac{1}{1-\alpha} \right) \right) < 0\]<p>Furthermore, if \(\text{H}(k'\theta) < k'\text{H}(\theta)\) the emergence curve from this expression dominates that derived from Theorem 3 above.</blockquote><figure><img loading=lazy src=/images/my_post_folder/emergence_curve3.jpg alt="Scenario 1: Across columns"><figcaption><p>Figure 10: see <a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a>. Performance curve for t-tuples of skills for for theta = 0.05 and t = 1, 2, 4 respectively.</p></figcaption></figure><p>By the illustration in [(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936): From corollary 4, we can conclude that if \(k'\theta\) is fixed, then we have same performance curve. It implies that the effect of reducing \(\theta\) by a factor 2 has the effect of raising competence on 2k'-tuples to at least the same level as what it was on k'-tuples before reducing \(\theta\).<p><strong>But how do we connect this with scaling law?</strong></p><p>By the illustration in [(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936): Assume (for simplicity) a Chinchilla-like scaling law that 10x up-scaling leads to factor 2 reduction in excess entropy. By theorem 2, we know \(\theta\) is proportional to excess cross entropy. So factor 2 reduction in \(\theta\) corresponds factor 2 reduction in excess entrop.<p>By the illustration in [(Sanjeev et al. 2023)](https://arxiv.org/pdf/2307.15936): If a model is considered to have reasonable performance on individual skill (1-tuple skills) at current scaling, then after further up-scaling of 10x(factor 2 reduction in \(\theta\)) one would see similar reasonable performance on skill-pairs (2-tuples of skills), and scaling up by yet another 10x after that will yield similar reasonable performance on 4-tuples of skills, etc.<p><strong>Thus we have the result: the performance curve inferred by our method for k’-tuples of skills after scaling up is identical to the curve inferred for individual skills without scaling up. That means the competence of complex skills after scaling is not that samll, which means complex skills that were not seen during training must emerge.</strong></p><p>The result is formalized as <strong>corollary 5</strong> below: You can find the proof is in the paper.</p><blockquote><p>Corollary 5: When the model M1 with loss \(\delta\) is scaled up (e.g., as per equation (3)) so that the new model M2 has loss \(\delta\)/k', then the performance curve inferred by our method for k'-tuples of skills using M2 is identical to the curve inferred for individual skills on model M1.</blockquote><h3 id=243-emergence-analysis-with-general-measure-on-text-and-skills>2.4.3 Emergence analysis with general measure on text and skills<a hidden class=anchor aria-hidden=true href=#243-emergence-analysis-with-general-measure-on-text-and-skills>#</a></h3><p><figure><img loading=lazy src=/images/my_post_folder/skill_cluster.png alt="Scenario 1: Across columns"><figcaption><p>Figure 11:Created by Xiaolan Liu. Skill graph where text pieces contain multiple skill clusters.</p></figcaption></figure>Many skill clusters, not just one
Each cluster has similar description as before, except skills
of one cluster could be present in text in another cluster
(e.g., ”Basic English” needed in ”Logic”)</p><p>Nothing much changes in theory, except now it only predicts
emergence within a cluster if/when excess loss in that cluster
goes down significantly.</p><hr><h1 id=part-3-appendix>Part 3: Appendix<a hidden class=anchor aria-hidden=true href=#part-3-appendix>#</a></h1><h2 id=31-theorem-1>3.1 Theorem 1<a hidden class=anchor aria-hidden=true href=#31-theorem-1>#</a></h2><blockquote><ul><li><p>If a model’s excess entropy at the ith place in text is ϵ then there is a cloze question with binary answer such that the probability that the model answers it incorrectly is at most \(\sqrt{2 \epsilon}\).</li></ul></blockquote><p><strong>Proof:</strong></p><p>Define \( p_i \) to be the human's probability for the \((i+1)\)-th word, \( q_i = \) model's probability for the \((i+1)\)-th word.<p><strong>Step 1:</strong></p><p>Show that the probability of \( p_i \) and \( q_i \) giving different answers is \( \max_A \left| \sum_{A} \left( p_i(w) - q_i(w) \right) \right| \), where \( A \) is any subset of words.<p>Pf of Step 1: Note that the human's probability \( p_i \) on \((i+1)\)-th word is:<p>\[
p_i(w) = P(W_{i+1} = w) = \begin{cases}
1, & \text{if } w = w^* \\ 
0, & \text{otherwise}
\end{cases}
\]<p>i.e., \( p_i(w^*) = 1 \), \( P_i(w) = 0 \) if \( w \neq w^* \)<p>So \( p_i \) will always answer \( w^* \).<p>The answer for \( q_i(\cdot) \) is \( \arg \max_w q_i(w) \), denoted as \( w^{**} \).<p>So in order to give different answers between \( p_i \) and \( q_i \), we need \( w^* \neq w^{**} \).<p><strong>Step 2:</strong></p><p>From Step 1:
$$
P(p_i \text{ and } q_i \text{ give different answers}) = \text{variation distance between } p_i \text{ and } g_i
$$</p><p>Using Pinsker&rsquo;s Theorem:
$$
\leq \sqrt{\frac{1}{2} KL(p_i \Vert q_i)} \leq \sqrt{\frac{1}{2} \epsilon}
$$</p><p>Construct the cloze question as follows:</p><p>Define \(A_{i+1}\) as:
$$
A_{i+1} = \arg \max_A \left| \sum_A (p_i(w) - q_i(w)) \right|
$$<p>Then, the cloze question is: Is the \((i+1)\)-th word \(w^*\) in \((a)\), \(A_{i+1}\), or \((b)\), in \(A_{i+1}^c\)?<p>$$
\text{Pr(answer to cloze question is wrong)} = P(w^* \in A_{i+1} \text{ but we answer } (b)) + P(w^* \in A_{i+1}^c \text{ but we answer } (a))
$$</p><p>$$
= P(p_i&rsquo;s \text{ answer is in } A_{i+1}, q_i&rsquo;s \text{ answer is in } A_{i+1}^c) + P(p_i&rsquo;s \text{ answer is in } A_{i+1}^c, q_i&rsquo;s \text{ answer is in } A_{i+1})
$$</p><p>$$
\leq P(p_i&rsquo;s \text{ answer is different from } q_i) + P(p_i&rsquo;s \text{ answer is different from } q_i)
$$</p><p>$$
= 2 P(p_i&rsquo;s \text{ answer is different from } q_i)
$$</p><p>If we denote \(p_i's \text{ answer is in } A_{i+1}, q_i's \text{ answer is in } A_{i+1}^c\) as \(E\),<p>\(p_i's \text{ answer is in } A_{i+1}^c, q_i's \text{ answer is in } A_{i+1}\) as \(F\),<p>\(p_i's \text{ answer is different from } q_i\) as \(G\).<p>Since both \(E\) and \(F\) are subsets of \(G\), if \(p_i's\) answer in \(A_{i+1}\), \(q_i's\) answer in \(A_{i+1}^c\).<p>Obviously answers are different,<p>$$
\Rightarrow E \subseteq G, \ F \subseteq G
$$</p><p>Then by Pinsker&rsquo;s Theorem above:</p><p>$$
\Rightarrow 2 \cdot \sqrt{\frac{1}{2} \epsilon} = \sqrt{2 \epsilon}
$$</p><h2 id=32-theorem2>3.2 Theorem2<a hidden class=anchor aria-hidden=true href=#32-theorem2>#</a></h2><blockquote><p><strong>Theorem 2</strong> : if the average excess cross-entropy loss for the text-pieces is δ we conclude Y consists of at most 2δ fraction of text pieces.</p></blockquote><p><strong>Proof:</strong></p><p>Assume there are \( N \) text pieces, each text piece has \( Q_i \) cloze questions.
\( \delta \) is the average ce loss.<p>\[
\delta = \frac{1}{N} \sum_{i=1}^N \text{cross entropy on text piece } i
\]<p>Since the ce loss on the text piece = the ce loss of cloze questions on this text piece,</p><p>\[
\Rightarrow \delta= \frac{1}{N} \sum_{i=1}^N \frac{1}{Q_i} \sum_{j=1}^{Q_i} \text{cross entropy on cloze question } z_j^{(i)}
\]<p>Since The average ce loss \(\geq\) the loss in subset \(Y\).<p>\[
\Rightarrow \delta \geq \frac{1}{N} \sum_{i \in Y} \frac{1}{Q_i} \sum_{j=1}^{Q_i} \text{cross entropy on cloze question } z_j^{(i)} := A_i
\]<p>Step 1: Prove that \( A_i \geq \frac{1}{2} \)<p>Step 2: Prove that \( \theta \leq 2\delta \)<p><strong>Pf of step 1:</strong></p><p>\[
A_i = \frac{1}{Q_i} \sum_{j=1}^{Q_i} \text{cross entropy on cloze question } z_j^{(i)}
\]<p>\[
= \frac{1}{Q_i} \sum_{j=1}^{Q_i} \sum_w -p_i(w) \log q_i(w)
\]<p>where \(w\) is all of the possible answers.<p>\[
= \frac{1}{Q_i} \left( \sum_{j=1}^{Q_i} \sum_w -p_i(w) \log q_i(w) \text{ (model is correct on } z_j^{(i)})
+ \sum_{j=1}^{Q_i} \sum_w -p_i(w) \log q_i(w) \text{ (model is wrong on } z_j^{(i)})\right)
\]<p>\[
\geq \frac{1}{Q_i} \sum_{j=1}^{Q_i} \sum_w -p_i(w) \log q_i(w)\text{ (model is wrong on } z_j^{(i)})
\]<p>Assume \(w*\) is the correct answer. \(\Rightarrow p_i(w^*) = 1, p_i(w) = 0 \text{ if } w \ne w^*\)<p>\[
\Rightarrow \frac{1}{Q_i} \sum_{j=1}^{Q_i} -\log q_i(w^*) \text{ (model is wrong on } z_j^{(i)})
\]<p>\(\text{Since model is wrong on } z_j^{(i)}\)<p>\[
\Rightarrow -\log q_i(w^*) \leq 1 \quad (\text{otherwise model will be correct})
\]<p>\[
\Rightarrow -\log q_i(w^*) \geq 1
\]<p>\[
\Rightarrow A_i = \frac{1}{Q_i} \sum_{j=1}^{Q_i} \left( -\log q_i(w^*) \right)\text{(model is wrong on } z_j^{(i)})
\]<p>\[
\geq \frac{1}{Q_i} \sum_{j=1}^{Q_i} 1 \text{(model is wrong on } z_j^{(i)})
\]<p>Define set \( S_i = \{z_j^{(i)} : \text{model is wrong on } z_j^{(i)}\} \)<p>Since \(Y\) is the set of text pieces with each has at least half of wrong cloze questions on it.<p>\[
\text{by definition } \Rightarrow |S_i| \geq \frac{1}{2} |Q_i|
\]<p>\[
\Rightarrow A_i \geq \frac{1}{Q_i} |S_i| \geq \frac{1}{2}
\]<p><strong>Pf of step 2:</strong></p><p>Since \( \delta \geq \frac{1}{N} \sum_{i \in Y} A_i \)<p>\[
\geq \frac{1}{N} \sum_{i \in Y} \frac{1}{2} \quad (\text{from step 1, } A_i \geq \frac{1}{2})
\]<p>\[
= \frac{1}{2N} |Y|
\]<p>\[
= \frac{1}{2N} \cdot \theta N
\]<p>\[
\Rightarrow \theta \leq 2 \delta
\]<h2 id=33-theorem-3>3.3 Theorem 3<a hidden class=anchor aria-hidden=true href=#33-theorem-3>#</a></h2><blockquote><p>Theorem 3: Let \(\alpha\),\(\beta\),\(\theta\) > 0, \(\beta\)> 1,\(\alpha\beta\) < 1,\(\theta\) < 1 satisfy:<p>\[\text{H}(\theta) + k \theta \left( \text{H}(\beta \alpha) - \beta \alpha \log \frac{1}{\alpha} - (1-\beta \alpha) \log \left( \frac{1}{1-\alpha} \right) \right) = 0\]<p>where \({H}(\theta)\) is Entropy defined as follows:<p>\[\text{H}(x) = x \log_2 \frac{1}{x} + (1-x) \log_2 \frac{1}{1-x} \tag{1}\]</blockquote><p><strong>Proof:</strong></p><p>We say model makes a mistake in a text piece if it fails to answer >= half of its cloze questions.</p><p>Suppose \(V1\) is the set for text pieces and \(V2\) is the set for skills. Suppose \(Y \subseteq V1\) of size \(\theta N1\) is the subset of text pieces where model makes mistakes. We need to show that thare are at least \((1-\alpha)\) fraction of vertices in \(V2\) each of which has at most \(\beta \theta D\) edges going to Y, where \(D=\frac{kN1}{N2}\).<p>Define a skill to be "good" if it has at most \(\beta\theta D\) edges going to Y, and "bad" if it has more than \(\beta\theta D\) edges going to Y.<p>So we need to show that there are at least \((1 - \alpha) N2\) good skills, or equivalently, show that there are at most \(\alpha N2\) fraction bad skills.<p>Define \(Z \subseteq V2, |Z2| \leq \alpha N2\) be the subset of \(V2\) such that \(Z\) has at least \(\alpha \beta \theta kN1\) edges to \(Y\). So \(Z\) is potentially the set for all "bad" skills. (Since \((\beta \theta D) * (\alpha N2) = \alpha \beta \theta kN1)\).<p>If we can show that the expected number of such \(Z\)s is at most 1, then we can conclude the theorem because we have at most 1 such bad subset of skills, each has at most \(\alpha N2\) bad skills, making it total at most \(\alpha N2\) bad skills in \(V2\).<p>By some combinatorics we conclude that the expected number of such \(Z\)s can be upper bounded by
$$
N1N2\binom{N2}{\alpha N2}\times \binom{N1}{\theta N1} \times \binom{k\theta N_1}{\beta \alpha k \theta N_1} \times\alpha^{\beta\alpha\theta kN_1}\times (1-\alpha)^{(1-\beta\alpha)\theta k N_1}
$$<p>Note that the latter three terms is the probability in binomial distribution that among total \(k\theta N_1\)outgoing edges from \(Y\), the probability of \(\beta \alpha k\theta N_1\) of them connect to the vertices in Z.<p>We need to show that the above formula can be upper bounded by 1, which can be shown by showing that the log of above is negative.<hr><h1 id=part-4-reference>Part 4: reference<a hidden class=anchor aria-hidden=true href=#part-4-reference>#</a></h1><p><a href=https://arxiv.org/pdf/2307.15936>(Sanjeev et al. 2023)</a></p><p><a href=http://www.lanais.famaf.unc.edu.ar/cursos/em/Anderson-MoreDifferent-1972.pdf>(Anderson, 1972)</a></p><p><a href=https://arxiv.org/pdf/2206.07682>(Wei et al. 2022)</a></p><p><a href=https://arxiv.org/pdf/2304.15004>(Schaeffer et al. 2023)</a></p><p><a href=https://arxiv.org/pdf/2309.01809>(Lu et al. 2023)</a></p><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://XIAOLAN-design.github.io/posts/papermod/papermod-features/><span class=title>« Prev</span><br><span>Features / Mods</span>
</a><a class=next href=https://XIAOLAN-design.github.io/posts/markdown-syntax/><span class=title>Next »</span><br><span>Markdown Syntax Guide</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Emergence of Complex Skills in Language Model on x" href="https://x.com/intent/tweet/?text=Emergence%20of%20Complex%20Skills%20in%20Language%20Model&amp;url=https%3a%2f%2fXIAOLAN-design.github.io%2fposts%2femergence%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Emergence of Complex Skills in Language Model on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fXIAOLAN-design.github.io%2fposts%2femergence%2f&amp;title=Emergence%20of%20Complex%20Skills%20in%20Language%20Model&amp;summary=Emergence%20of%20Complex%20Skills%20in%20Language%20Model&amp;source=https%3a%2f%2fXIAOLAN-design.github.io%2fposts%2femergence%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Emergence of Complex Skills in Language Model on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fXIAOLAN-design.github.io%2fposts%2femergence%2f&title=Emergence%20of%20Complex%20Skills%20in%20Language%20Model"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Emergence of Complex Skills in Language Model on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fXIAOLAN-design.github.io%2fposts%2femergence%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Emergence of Complex Skills in Language Model on whatsapp" href="https://api.whatsapp.com/send?text=Emergence%20of%20Complex%20Skills%20in%20Language%20Model%20-%20https%3a%2f%2fXIAOLAN-design.github.io%2fposts%2femergence%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Emergence of Complex Skills in Language Model on telegram" href="https://telegram.me/share/url?text=Emergence%20of%20Complex%20Skills%20in%20Language%20Model&amp;url=https%3a%2f%2fXIAOLAN-design.github.io%2fposts%2femergence%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Emergence of Complex Skills in Language Model on ycombinator" href="https://news.ycombinator.com/submitlink?t=Emergence%20of%20Complex%20Skills%20in%20Language%20Model&u=https%3a%2f%2fXIAOLAN-design.github.io%2fposts%2femergence%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>© <a href=https://github.com/adityatelange/hugo-PaperMod/graphs/contributors>PaperMod Contributors</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>